version: "3.9"

services:
  app:
    build: ./core
    command: uvicorn core.main:app --host 0.0.0.0 --port 8000
    volumes:
      - data:/app/data
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=/app/data/flight.db
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_MODEL=qwen2.5-coder:3b
      - EXTERNAL_API_URL=http://external_api:8081/customers
    depends_on:
      - ollama
      - external_api

  tests:
    build: ./core
    command: pytest -v
    volumes:
      - data:/app/data
    environment:
      - DATABASE_PATH=/app/data/flight_test.db
    depends_on:
      - app

  ollama:
    image: ollama/ollama
    container_name: ollama
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    volumes:
      - ollama:/root/.ollama
      - ./ollama_server/start.sh:/ollama_entrypoint.sh
    ports:
      - "11434:11434"
    environment:
      - LLM_MODEL_VERSION=qwen2.5-coder:3b
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    entrypoint: [ "/bin/bash", "/ollama_entrypoint.sh" ]
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:11434 || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 5

  external_api:
    build: ./externalapi
    ports:
      - "8081:8081"

volumes:
  ollama:
  data:
